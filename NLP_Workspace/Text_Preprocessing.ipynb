{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3e52cc5-5e5e-4b27-aca2-8570939d6741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6253ed7f-d73d-482f-9227-b2b496a58524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f53e42fe-1d72-45cf-8b11-5492a38c6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be527a50-540e-4525-bbd6-b59487bb688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e15619-a110-42c7-8369-19d7416bac93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c2742d-beec-41f0-844f-c0973ad8b83a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Converting texts into lowercase to treat all as same entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb9c2f9-cf61-450b-8d8a-7d95a78f98b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>daniel day-lewis is the most versatile actor a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>my guess would be this was originally going to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>well, i like to watch bad horror b-movies, cau...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>this is the worst movie i have ever seen, as w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>i have been a mario fan for as long as i can r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review sentiment\n",
       "0   one of the other reviewers has mentioned that ...  positive\n",
       "1   a wonderful little production. <br /><br />the...  positive\n",
       "2   i thought this was a wonderful way to spend ti...  positive\n",
       "3   basically there's a family where a little boy ...  negative\n",
       "4   petter mattei's \"love in the time of money\" is...  positive\n",
       "..                                                ...       ...\n",
       "95  daniel day-lewis is the most versatile actor a...  positive\n",
       "96  my guess would be this was originally going to...  negative\n",
       "97  well, i like to watch bad horror b-movies, cau...  negative\n",
       "98  this is the worst movie i have ever seen, as w...  negative\n",
       "99  i have been a mario fan for as long as i can r...  positive\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"]=df[\"review\"].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c5cbf0-d04e-428f-8d73-2dc23be17e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"review\"][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c8f86-da2c-4ffe-889d-053d4b54573f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Removal & Replacing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "520e6e42-0f13-4a3d-97f5-7cd2a5d413a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re                                                   #import regular expression\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')                           #creates a regex pattern object for reuse.\n",
    "    return pattern.sub(r'', text)                           #sub is about substitute and r is to treat string as raw not to treat as escape character\\."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baffd8c1-fd8d-4db9-ad96-eaef68c2cf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Chetan N Revankar'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tags = \"<html><body><p>My name is Chetan N Revankar</p></body></html>\"\n",
    "remove_html_tags(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c83e7bde-7b9a-482c-adea-51939542f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02b81644-7a76-4460-bcdc-b9cd41f1edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if you like original gut wrenching laughter you will like this movie. if you are young or old then you will love this movie, hell even my mom liked it.great camp!!!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af54457-5564-4d72-8161-a4cbbe3a31c8",
   "metadata": {},
   "source": [
    "## Removal of URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2928820-d5f8-47a9-95fd-66657da1776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My LinkedIN:'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+')                 # https?:// matches http:// or https:// links \\S+ Matches one or more non space characters\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "sample_url = \"My LinkedIN:https://www.linkedin.com/in/chetannrevankar\"\n",
    "remove_url(sample_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e691d50f-35a2-4b77-880b-3e0974f2b20d",
   "metadata": {},
   "source": [
    "## Punctuation Handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9abcae03-c0ce-44d8-a8fc-98429a0eb2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string, time\n",
    "exclude = string.punctuation\n",
    "exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc88ce7d-35bf-449a-98fa-a2438d58f4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Chetan N Revankar'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "\n",
    "sample_pt = \"My name is $Chetan N Revankar\"\n",
    "remove_punc(sample_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca98a93d-2cdd-477a-a611-fc2b9bc211fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Chetan N Revankar'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('','',exclude))       #Fastest method to replace\n",
    "\n",
    "remove_punc1(sample_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86911745-79c9-4d8d-9757-785c5f54ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     one of the other reviewers has mentioned that ...\n",
       "1     a wonderful little production the filming tech...\n",
       "2     i thought this was a wonderful way to spend ti...\n",
       "3     basically theres a family where a little boy j...\n",
       "4     petter matteis love in the time of money is a ...\n",
       "                            ...                        \n",
       "95    daniel daylewis is the most versatile actor al...\n",
       "96    my guess would be this was originally going to...\n",
       "97    well i like to watch bad horror bmovies cause ...\n",
       "98    this is the worst movie i have ever seen as we...\n",
       "99    i have been a mario fan for as long as i can r...\n",
       "Name: review, Length: 100, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = remove_punc(df['review'])\n",
    "df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc12fa-23fa-4c7b-9159-3c1b3926624c",
   "metadata": {},
   "source": [
    "## Chat words Conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e4a48dd-2855-4d43-bb03-cb7a22275391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'll be attending the interview tomorrow As Soon As Possible\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words = {\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"OMG\": \"Oh My God\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IMHO\": \"In My Humble Opinion\",\n",
    "    \"IDK\": \"I Don't Know\",\n",
    "    \"TMI\": \"Too Much Information\",\n",
    "    \"ICYMI\": \"In Case You Missed It\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"TGIF\": \"Thank God It's Friday\",\n",
    "    \"FYA\": \"For Your Action\",\n",
    "    \"GTG\": \"Got To Go\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"TTYT\": \"Talk To You Tomorrow\",\n",
    "    \"LOL\": \"Laugh Out Loud\",\n",
    "    \"TBH\": \"To Be Honest\",\n",
    "    \"NGL\": \"Not Gonna Lie\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"ETA\": \"Estimated Time of Arrival\",\n",
    "    \"LMK\": \"Let Me Know\",\n",
    "    \"FYR\": \"For Your Reference\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"LMAO\": \"Laughing My Ass Off\",\n",
    "    \"TTYS\": \"Talk To You Soon\",\n",
    "    \"SMH\": \"Shaking My Head\",\n",
    "    \"IDC\": \"I Don't Care\",\n",
    "    \"IIRC\": \"If I Recall Correctly\",\n",
    "    \"JK\": \"Just Kidding\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "}\n",
    "\n",
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "chat_conversion(\"I'll be attending the interview tomorrow ASAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e48bf6-55ef-433b-b2a2-69f7188ad389",
   "metadata": {},
   "source": [
    "## Spelling mistake handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "977d4341-65f3-4486-81df-a737d7b8ac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am Graduated from RNSIT, in the branch of CSE.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob                     #Library to handle the spelling mistake\n",
    "incorrect_text = \"I am Grduated frm RNSIT, in the banch of CSE.\"\n",
    "textblb = TextBlob(incorrect_text)\n",
    "textblb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32211cca-3ee6-403d-91cb-cdcc2e0df3c2",
   "metadata": {},
   "source": [
    "## Stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "65199590-8ce2-4ca3-9c87-f65d113b125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d9d9cab-85d9-4299-a396-970e389f5e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1940ef85-3432-40db-afee-b5c0ee7babc1",
   "metadata": {},
   "source": [
    "Stopwords are common filler words (like the, is, at, of, and) that don’t add much meaning. They are usually removed in NLP to focus on important words for analysis. It also increases the dimension of the dataset so if we remove it helps to reduce the computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7df4ffce-bbbe-4cc0-b32f-a4af014bc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \" \".join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "879a9856-5d9d-4dc0-978c-d48592753b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name  Chetan N Revankar,  going   Data Engineer  soon  possible.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords('My name is Chetan N Revankar, am going to be Data Engineer as soon as possible.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48019b88-6457-4d17-b70d-db88988bdd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e26c3328-1015-4cd8-a7b9-efc588ae2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "61260b2d-32af-4786-9021-c45f5ab44219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     one    reviewers  mentioned   watching  1 oz e...\n",
       "1      wonderful little production  filming techniqu...\n",
       "2      thought    wonderful way  spend time    hot s...\n",
       "3     basically theres  family   little boy jake thi...\n",
       "4     petter matteis love   time  money   visually s...\n",
       "                            ...                        \n",
       "95    daniel daylewis    versatile actor alive engli...\n",
       "96     guess would    originally going    least two ...\n",
       "97    well  like  watch bad horror bmovies cause  th...\n",
       "98       worst movie   ever seen  well   worst    pr...\n",
       "99        mario fan   long    remember    fond memor...\n",
       "Name: review, Length: 100, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1208a8-c55d-4597-9047-3846641ed923",
   "metadata": {},
   "source": [
    "## Remove Emoji's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3e5a8cf9-5981-4e3e-b98b-44c3f817c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"  # other symbols\n",
    "                           u\"\\U000024C2-\\U0001F251\"  # enclosed characters\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    return emoji_pattern.sub(r'', text)   # replace emojis with empty string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65e5e31b-aa13-4006-b926-685d41dd773b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Am a data engineer '"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"Am a data engineer 💻📊🚀\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a3a2fcdb-08a5-462b-af0d-017e5e355bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/590.6 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/590.6 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 262.1/590.6 kB ? eta -:--:--\n",
      "   -------------------------------------- 590.6/590.6 kB 446.9 kB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6de99418-cafd-4d36-a24d-5a9f4f00de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data speaks truth:light_bulb::speaking_head:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('Data speaks truth💡🗣️'))   #demojize used to know the meaning of the emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd0cdd-3d95-42b1-99f2-eaf6e17e72fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Tokenization:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5b7bcd-8914-4427-bc23-c401ad960695",
   "metadata": {},
   "source": [
    "### 1. Using the split function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a98355a5-3efe-4f31-b3f3-ebb7d6c8a561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'Chetan', 'N', 'Revankar']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am Chetan N Revankar\"\n",
    "sentence.split()                        #word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d7b0d05c-e101-4597-a6db-2f52f93984c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am Chetan N Revankar', ' Future Data Engineer', '']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1 = \"I am Chetan N Revankar. Future Data Engineer.\"\n",
    "sentence1.split('.')                                              #sentence tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae342485-a6e5-4932-b8c8-3deb9aa1d25d",
   "metadata": {},
   "source": [
    "### 2. Using Regular Expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9c3ed794-5397-4fdf-a7d4-c1afad77c8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "C:\\Users\\cheta\\AppData\\Local\\Temp\\ipykernel_10068\\3330481511.py:3: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  tokens = re.findall(\"[\\w]+\", sentence2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'Dubai']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sentence2 = \"I am going to Dubai\"\n",
    "tokens = re.findall(\"[\\w]+\", sentence2)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4a8cd312-8538-4a51-bba6-36479ac1efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Generative AI (GenAI) is a branch of artificial intelligence that can create new content such as text, images, code, or music by learning patterns from existing data',\n",
       " 'It uses advanced models like Large Language Models (LLMs) and Generative Adversarial Networks (GANs) to mimic human-like creativity',\n",
       " 'GenAI is widely applied in chatbots, content creation, design, and automation.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Generative AI (GenAI) is a branch of artificial intelligence that can create new content such as text, images, code, or music by learning patterns from existing data. It uses advanced models like Large Language Models (LLMs) and Generative Adversarial Networks (GANs) to mimic human-like creativity. GenAI is widely applied in chatbots, content creation, design, and automation.\"\n",
    "sentences = re.compile('[.!?] ').split(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975ef07-eb29-43f9-9ece-429978d0a101",
   "metadata": {},
   "source": [
    "### 3. NLTK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9ce28c2c-72a6-47e0-9c14-f524cf904222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c13484b-e835-4cf7-b8f2-9d15fa6885af",
   "metadata": {},
   "source": [
    "`word_tokenize` splits a sentence into individual words/tokens.\n",
    "\n",
    "`sent_tokenize` splits a paragraph/text into sentences.\n",
    "\n",
    "`Punkt` is a pre-trained, unsupervised tokenizer model in NLTK used for splitting text into sentences and words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "311490a3-23c5-4dd7-b32b-b9481e38f3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'Chetan', 'N', 'Revankar', '.', 'Future', 'Data', 'Engineer', '.']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"I am Chetan N Revankar. Future Data Engineer.\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "27435e51-a5fc-4be8-93bc-44439f7974b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am Chetan N Revankar.', 'Future Data Engineer.']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e245e219-081c-4dc3-935e-0e0d78ca6631",
   "metadata": {},
   "source": [
    "### 4. Spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f282ef6c-09d9-4da4-849e-f27405ee162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "057a8a91-2434-4811-b6c9-2e1862b1ad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I am Chetan N Revankar. Future Data Engineer."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(sent1)\n",
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a75bf0ae-6cbc-4a5e-ad85-381364edd698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "am\n",
      "Chetan\n",
      "N\n",
      "Revankar\n",
      ".\n",
      "Future\n",
      "Data\n",
      "Engineer\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff61444-9855-4b10-b139-7f8c6db9d996",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Stemmer:\n",
    "Stemming is about reducing words to their root form (often crude), mainly to normalize text for NLP tasks like search or classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d0cb68e-c8c4-4a6a-ac27-697b7a0a4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ff398-b574-422e-b2d3-768f44b8b937",
   "metadata": {},
   "source": [
    "`nltk` Python library for NLP tasks like tokenization, stemming, lemmatization, stopword removal.\n",
    "\n",
    "`stem` Submodule in NLTK with stemming algorithms (reduce words to root).\n",
    "\n",
    "`porter` Porter algorithm removes common endings (-ing, -ed, -s, -ly).\n",
    "\n",
    "`PorterStemmer` Class in NLTK that applies Porter algorithm for stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a6ced4-6781-4dc7-9d25-35686ed2ff04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run runner run easili\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer  \n",
    "\n",
    "ps = PorterStemmer()  \n",
    "\n",
    "def stem_words(text):\n",
    "    words = text.split()                              # Step 1: split text into words\n",
    "    stemmed_words = [ps.stem(w) for w in words]       # Step 2: stem each word\n",
    "    return \" \".join(stemmed_words)                    # Step 3: join back into sentence\n",
    "\n",
    "print(stem_words(\"running runner runs easily\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961504ab-4881-47fb-86c1-76ab78ecb7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"my name is chetan n revankar from bangalore, rajajinagar. i recent complet my bachelor' degre from rnsit with an aggreg of 8.23cgpa.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"My name is Chetan N Revankar from Bangalore, Rajajinagar. I recently completed my Bachelor's Degree from RNSIT with an aggregate of 8.23CGPA.\"\n",
    "stem_words(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487466f2-0d14-4b24-ba38-ce1e3e41551c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Lemmatization:\n",
    "Process of reducing words to their base or dictionary form (lemma) using vocabulary and grammar rules, ensuring meaningful words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfba48d-1b0d-49aa-9350-9c05fd6533f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\cheta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "My                  My                  \n",
      "name                name                \n",
      "is                  be                  \n",
      "Chetan              Chetan              \n",
      "N                   N                   \n",
      "Revankar            Revankar            \n",
      "from                from                \n",
      "Bangalore           Bangalore           \n",
      "Rajajinagar         Rajajinagar         \n",
      "I                   I                   \n",
      "recently            recently            \n",
      "completed           complete            \n",
      "my                  my                  \n",
      "Bachelor            Bachelor            \n",
      "'s                  's                  \n",
      "Degree              Degree              \n",
      "from                from                \n",
      "RNSIT               RNSIT               \n",
      "with                with                \n",
      "an                  an                  \n",
      "aggregate           aggregate           \n",
      "of                  of                  \n",
      "8.23CGPA            8.23CGPA            \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')     # WordNet database for lemmatization\n",
    "nltk.download('omw-1.4')     # additional language support\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "text = \"My name is Chetan N Revankar from Bangalore, Rajajinagar. I recently completed my Bachelor's Degree from RNSIT with an aggregate of 8.23CGPA.\"\n",
    "\n",
    "punctuations = \"?:!.,;\"\n",
    "\n",
    "# Step 1: Tokenize text (split into words + punctuation)\n",
    "sentence_words = nltk.word_tokenize(text)\n",
    "\n",
    "# Step 2: Remove punctuation\n",
    "filtered_words = [word for word in sentence_words if word not in punctuations]\n",
    "\n",
    "# Step 3: Print original word and its lemmatized form (as verb)\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in filtered_words:\n",
    "    print(\"{0:20}{1:20}\".format(word, wordnet_lemmatizer.lemmatize(word, pos='v')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb5118-9cbc-4e79-a0c2-fb2faf01cc49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
